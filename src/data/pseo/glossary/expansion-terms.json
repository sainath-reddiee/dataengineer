[
    {
        "term": "Lakehouse Architecture",
        "slug": "lakehouse",
        "category": "data-warehousing",
        "shortDefinition": "A modern data architecture that combines the performance and governance of data warehouses with the low-cost and flexibility of data lakes.",
        "fullDefinition": "The Lakehouse architecture is an attempt to merge the best of both worlds: the structure and ACID compliance of a Data Warehouse with the scalability and cost-efficiency of a Data Lake. It usually sits on top of open table formats like Delta Lake or Apache Iceberg.",
        "keyPoints": [
            "ACID transactions on object storage (S3/GCS)",
            "Supports both BI (SQL) and AI/ML (Python/Spark)",
            "Eliminates data silos by having one source of truth",
            "Low-cost storage with high-performance query engines"
        ]
    },
    {
        "term": "Infrastructure as Code (IaC)",
        "slug": "iac",
        "category": "cloud-platforms",
        "shortDefinition": "The practice of managing and provisioning infrastructure through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools.",
        "fullDefinition": "IaC allows data engineers to treat their infrastructure (S3 buckets, EC2 nodes, Snowflake warehouses) exactly like their application code. This enables version control, automated testing, and repeatable deployments.",
        "keyPoints": [
            "Repeatability and Consistency",
            "Version Control (Git) support",
            "Automated scaling and management",
            "Tools include Terraform, Pulumi, and AWS CDK"
        ]
    },
    {
        "term": "OLAP (Online Analytical Processing)",
        "slug": "olap",
        "category": "analytics",
        "shortDefinition": "A category of software tools that provide analysis of data stored in a database, typically for multi-dimensional business reporting.",
        "fullDefinition": "OLAP databases are optimized for 'Reads'. They are designed to aggregate millions or billions of rows in seconds. Unlike OLTP (Postgres), they usually store data in columns to optimize for wide-scanning queries.",
        "keyPoints": [
            "Columnar storage optimization",
            "Heavy use of compression",
            "Designed for complex aggregation queries",
            "Examples: ClickHouse, Pinot, StarRocks"
        ]
    },
    {
        "term": "Stateful Processing",
        "slug": "stateful-processing",
        "category": "streaming",
        "shortDefinition": "A stream processing technique where the application remembers information across multiple events in time.",
        "fullDefinition": "In streaming, 'stateless' operations just look at one event. 'Stateful' operations (like a running sum or tracking a user session) require the engine to keep local state. Flink is famous for its robust state management.",
        "keyPoints": [
            "Crucial for windowing and joins",
            "Requires high-performance local storage (RocksDB)",
            "Complex to scale and recover from failure",
            "The 'holy grail' of real-time engineering"
        ]
    },
    {
        "term": "Table Format",
        "slug": "table-format",
        "category": "data-warehousing",
        "shortDefinition": "A layer that organizes files in a data lake into a structured table, enabling SQL-like features like ACID and time-travel.",
        "fullDefinition": "Table formats like Iceberg, Hudi, and Delta Lake sit on top of Parquet files to provide metadata. This metadata allows query engines to know which files belong to a table, enabling ACID transactions and hidden partitioning.",
        "keyPoints": [
            "Enables ACID compliance on S3/GCS",
            "Supports Schema Evolution and Time Travel",
            "Engine agnostic (usually)",
            "Replaces the legacy Hive Metastore approach"
        ]
    }
]