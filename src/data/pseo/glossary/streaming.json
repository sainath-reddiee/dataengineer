[
  {
    "id": "kafka",
    "term": "Apache Kafka",
    "slug": "apache-kafka",
    "category": "streaming",
    "shortDefinition": "A distributed event streaming platform used for building real-time data pipelines and streaming applications, handling trillions of events per day.",
    "fullDefinition": "Apache Kafka is a distributed event streaming platform capable of handling trillions of events per day. Originally developed at LinkedIn, Kafka is now used by thousands of companies for real-time data pipelines, streaming analytics, and event-driven architectures.\n\n## Core Concepts\n\n### Topics\nData streams are organized into **topics**—named feeds of messages:\n- Producers write to topics\n- Consumers read from topics\n- Topics can have multiple partitions for parallelism\n\n### Partitions\nTopics are split into partitions for scalability:\n- Each partition is an ordered, immutable sequence of records\n- Consumers can read partitions in parallel\n- Partition count determines parallelism\n\n### Consumer Groups\nConsumers form groups to divide work:\n- Each partition is consumed by exactly one consumer in the group\n- Allows horizontal scaling of consumers\n- Multiple groups can read the same topic independently\n\n## Kafka Architecture\n\n```\nProducers → [Topic: orders] → Consumers\n                  │\n            ┌─────┴─────┐\n            │ Partition │\n            │     0     │\n            ├───────────┤\n            │ Partition │\n            │     1     │\n            ├───────────┤\n            │ Partition │\n            │     2     │\n            └───────────┘\n```\n\n## Key Features\n\n- **High Throughput**: Millions of messages per second\n- **Low Latency**: Sub-millisecond message delivery\n- **Durability**: Data replicated across brokers\n- **Scalability**: Add brokers without downtime\n- **Fault Tolerance**: Automatic leader election\n\n## Kafka Ecosystem\n\n- **Kafka Connect**: Pre-built connectors to data sources/sinks\n- **Kafka Streams**: Stream processing library\n- **ksqlDB**: SQL interface for stream processing\n- **Schema Registry**: Manage message schemas\n\n## Kafka Use Cases\n\n1. **Event Sourcing**: Store all state changes as events\n2. **Change Data Capture (CDC)**: Capture database changes\n3. **Microservices Communication**: Async event-driven messaging\n4. **Real-time Analytics**: Process events as they arrive\n5. **Log Aggregation**: Collect logs from distributed systems",
    "keyPoints": [
      "Distributed event streaming platform",
      "Handles millions of messages per second with low latency",
      "Core concepts: Topics, Partitions, Consumer Groups",
      "Foundation for real-time data pipelines",
      "Ecosystem includes Connect, Streams, and ksqlDB"
    ],
    "faqs": [
      {
        "question": "What is Apache Kafka used for?",
        "answer": "Kafka is used for building real-time data pipelines and streaming applications. Common use cases include event sourcing, log aggregation, change data capture (CDC), and microservices communication."
      },
      {
        "question": "Is Kafka a message queue?",
        "answer": "Kafka can function as a message queue, but it is more accurately an event log. Unlike traditional queues, Kafka retains messages after consumption, allowing replay and multiple consumer groups."
      },
      {
        "question": "What is a Kafka topic?",
        "answer": "A topic is a named stream of events in Kafka. Producers write events to topics, and consumers subscribe to topics to read events. Topics are divided into partitions for parallelism."
      },
      {
        "question": "Is Kafka difficult to learn?",
        "answer": "Kafka basic concepts can be learned quickly, but mastering it takes time. Key challenges include understanding partitioning, consumer groups, replication, and operational best practices."
      }
    ],
    "relatedTerms": [
      "streaming",
      "event-driven",
      "data-pipeline",
      "apache-spark",
      "cdc"
    ],
    "relatedTools": [
      "Confluent",
      "AWS MSK",
      "Redpanda",
      "Apache Pulsar",
      "RabbitMQ"
    ],
    "externalLinks": [
      {
        "title": "Apache Kafka Documentation",
        "url": "https://kafka.apache.org/documentation/"
      },
      {
        "title": "Confluent Developer Tutorials",
        "url": "https://developer.confluent.io/tutorials/"
      }
    ],
    "keywords": [
      "apache kafka",
      "kafka streaming",
      "kafka topics",
      "kafka vs rabbitmq",
      "kafka tutorial"
    ],
    "lastUpdated": "2026-01-21"
  },
  {
    "term": "Stateful Processing",
    "slug": "stateful-processing",
    "category": "streaming",
    "shortDefinition": "A stream processing technique where the application remembers information across multiple events in time.",
    "fullDefinition": "In streaming, 'stateless' operations just look at one event. 'Stateful' operations (like a running sum or tracking a user session) require the engine to keep local state. Flink is famous for its robust state management.",
    "keyPoints": [
      "Crucial for windowing and joins",
      "Requires high-performance local storage (RocksDB)",
      "Complex to scale and recover from failure",
      "The 'holy grail' of real-time engineering"
    ]
  },
  {
    "term": "Apache Flink",
    "slug": "apache-flink",
    "category": "streaming",
    "shortDefinition": "A distributed stream processing framework that processes data event-by-event with millisecond latency, built for stateful computations over unbounded data streams.",
    "fullDefinition": "**Apache Flink** is a distributed processing engine for stateful computations over both bounded (batch) and unbounded (streaming) data. Unlike Spark's micro-batch approach, Flink processes each event individually as it arrives, achieving true **millisecond-level latency**.\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────┐\n│              Flink Cluster                  │\n│  ┌──────────┐   ┌────────────────────────┐  │\n│  │JobManager│──→│     TaskManagers       │  │\n│  │(Master)  │   │ ┌──────┐ ┌──────┐     │  │\n│  │          │   │ │Slot 1│ │Slot 2│ ... │  │\n│  └──────────┘   │ └──────┘ └──────┘     │  │\n│                  └────────────────────────┘  │\n└─────────────────────────────────────────────┘\n```\n\n## Core Concepts\n\n### Event Time vs Processing Time\nFlink distinguishes between:\n- **Event Time**: When the event actually occurred (embedded in the data)\n- **Processing Time**: When Flink processes the event\n- **Ingestion Time**: When the event enters Flink\n\nThis matters for handling **late-arriving data** correctly.\n\n### State Management\nFlink's killer feature is its state management:\n- **Keyed State**: State partitioned by key (e.g., per-user counters)\n- **Operator State**: State per parallel operator instance\n- **State Backends**: RocksDB (disk) or HashMaps (memory)\n- **Checkpointing**: Automatic, consistent snapshots for fault tolerance\n\n### Windowing\nGroup events into time-based or count-based windows:\n- **Tumbling Windows**: Fixed-size, non-overlapping (every 5 minutes)\n- **Sliding Windows**: Fixed-size, overlapping (5-min window every 1 minute)\n- **Session Windows**: Dynamic, gap-based (close after 30min idle)\n- **Global Windows**: Custom trigger logic\n\n## Flink APIs (High to Low Level)\n\n| API | Level | Use Case |\n|-----|-------|----------|\n| Flink SQL | Highest | SQL queries on streams |\n| Table API | High | Relational operations |\n| DataStream API | Low | Custom stream processing |\n| ProcessFunction | Lowest | Full control over time and state |\n\n## Use Cases\n\n1. **Fraud Detection**: Sub-second pattern matching on transactions\n2. **Real-time Recommendations**: Update user profiles in real-time\n3. **IoT Analytics**: Process millions of sensor events per second\n4. **CDC Processing**: React to database changes instantly\n5. **Ad-tech Bidding**: Make bid decisions in milliseconds",
    "keyPoints": [
      "True event-by-event stream processing with millisecond latency",
      "Best-in-class stateful processing with RocksDB state backend",
      "Advanced windowing: tumbling, sliding, session, and global windows",
      "Handles late-arriving and out-of-order data via event time processing",
      "Unified batch and streaming with a single API"
    ],
    "faqs": [
      {
        "question": "What is Apache Flink used for?",
        "answer": "Flink is used for real-time stream processing applications that require low latency and stateful computations — such as fraud detection, real-time recommendations, IoT analytics, and event-driven microservices."
      },
      {
        "question": "Is Apache Flink better than Spark?",
        "answer": "For true real-time streaming with sub-second latency, Flink is superior. For batch processing and unified analytics workloads, Spark has a larger ecosystem. Many organizations use both."
      },
      {
        "question": "What is stateful processing in Flink?",
        "answer": "Stateful processing means Flink remembers information across events — like running totals, user sessions, or pattern matching. Flink manages this state with automatic checkpointing and exactly-once guarantees."
      },
      {
        "question": "Is Flink hard to learn?",
        "answer": "Flink SQL is easy for SQL-proficient users. The DataStream API has a steeper learning curve, especially concepts like watermarks, state management, and windowing. Starting with Flink SQL is recommended."
      }
    ],
    "relatedTerms": [
      "apache-kafka",
      "apache-spark",
      "stateful-processing",
      "cdc"
    ],
    "relatedTools": [
      "Apache Kafka",
      "Confluent",
      "Amazon Kinesis",
      "Databricks",
      "Ververica"
    ],
    "externalLinks": [
      {
        "title": "Apache Flink Documentation",
        "url": "https://nightlies.apache.org/flink/flink-docs-stable/"
      },
      {
        "title": "Flink Training Exercises",
        "url": "https://github.com/apache/flink-training"
      }
    ],
    "keywords": [
      "apache flink",
      "flink streaming",
      "flink vs spark",
      "flink stateful processing",
      "flink tutorial"
    ],
    "lastUpdated": "2026-02-27"
  }
]
